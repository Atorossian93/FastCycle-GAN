{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cycle-GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Schema Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to create in a simple format the schema of the solution proposed to colorize pictures with a Cycle-GAN accelerated with FFT convolutions.<p>To create a simple model schema this notebook will present the code for a Cycle-GAN built as a MVP (Minimum Viable Product) that works with the problem proposed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os \n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from skimage import color\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, BatchNormalization, UpSampling2D, Dropout, Flatten, Dense, Input, LeakyReLU, Conv2DTranspose,AveragePooling2D, Concatenate\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from tensorflow.compat.v1 import set_random_seed\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import keras.backend as K\n",
    "import boto3\n",
    "import time\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%capture` not found.\n"
     ]
    }
   ],
   "source": [
    "#import tqdm seperately and use jupyter notebooks %%capture\n",
    "%%capture\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter your bucket name and use boto3 to identify your region if you don't know it\n",
    "bucket = None\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_execution_role' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-84e33daffc65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#add your bucket then creat the containers to download files and send to bucket\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mrole\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_execution_role\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbucket\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;31m# customize to your bucket\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_execution_role' is not defined"
     ]
    }
   ],
   "source": [
    "#add your bucket then creat the containers to download files and send to bucket\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "bucket = None # customize to your bucket\n",
    "containers = {'us-west-2': '433757028032.dkr.ecr.us-west-2.amazonaws.com/image-classification:latest',\n",
    "              'us-east-1': '811284229777.dkr.ecr.us-east-1.amazonaws.com/image-classification:latest',\n",
    "              'us-east-2': '825641698319.dkr.ecr.us-east-2.amazonaws.com/image-classification:latest',\n",
    "              'eu-west-1': '685385470294.dkr.ecr.eu-west-1.amazonaws.com/image-classification:latest'}\n",
    "training_image = containers[boto3.Session().region_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Required parameter name not set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-298d23c47f48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# MPII Human Pose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://datasets.d2.mpi-inf.mpg.de/andriluka14cvpr/mpii_human_pose_v1.tar.gz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mupload_to_s3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'people'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mpii_human_pose_v1.tar.gz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m#untar the file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-298d23c47f48>\u001b[0m in \u001b[0;36mupload_to_s3\u001b[1;34m(channel, file)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchannel\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0ms3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBucket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbucket\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mput_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\boto3\\resources\\factory.py\u001b[0m in \u001b[0;36mcreate_resource\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m             return partial(resource_cls, *positional_args,\n\u001b[1;32m--> 474\u001b[1;33m                            client=self.meta.client)(*args, **kwargs)\n\u001b[0m\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[0mcreate_resource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\boto3\\resources\\base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midentifier\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m                 raise ValueError(\n\u001b[1;32m--> 119\u001b[1;33m                     'Required parameter {0} not set'.format(identifier))\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Required parameter name not set"
     ]
    }
   ],
   "source": [
    "def download(url):\n",
    "    '''\n",
    "    Downloads the file of a given url\n",
    "    '''\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "        \n",
    "def upload_to_s3(channel, file):\n",
    "    '''\n",
    "    Save file in a given folder in the S3 bucket\n",
    "    '''\n",
    "    s3 = boto3.resource('s3')\n",
    "    data = open(file, \"rb\")\n",
    "    key = channel + '/' + file\n",
    "    s3.Bucket(bucket).put_object(Key=key, Body=data)\n",
    "\n",
    "\n",
    "# MPII Human Pose\n",
    "download('https://datasets.d2.mpi-inf.mpg.de/andriluka14cvpr/mpii_human_pose_v1.tar.gz')\n",
    "upload_to_s3('people', 'mpii_human_pose_v1.tar.gz')\n",
    "\n",
    "#untar the file\n",
    "!tar xvzf mpii_human_pose_v1.tar.gz\n",
    "\n",
    "\n",
    "#MIT coastal \n",
    "download('http://cvcl.mit.edu/scenedatabase/coast.zip')\n",
    "upload_to_s3('coast', 'coast.zip')\n",
    "\n",
    "#unzip the file\n",
    "!unzip coast.zip -d ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_read(file, size=(256,256)):\n",
    "    '''\n",
    "    This function loads and resizes the image to the passed size.\n",
    "    Default image size is set to be 256x256\n",
    "    '''\n",
    "    image = image.load_img(file, target_size=size)\n",
    "    image = image.img_to_array(img)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_convert(file_paths,size=256,channels=3):\n",
    "    '''\n",
    "    Redimensions images to Numpy arrays of a certain size and channels. Default values are set to 256x256x3 for coloured\n",
    "    images.\n",
    "    Parameters:\n",
    "    file_paths: a path to the image files\n",
    "    size: an int or a 2x2 tuple to define the size of an image\n",
    "    channels: number of channels to define in the numpy array\n",
    "    '''\n",
    "    # If size is an int\n",
    "    if isinstance(size, int):\n",
    "        # build a zeros matrix of the size of the image\n",
    "        all_images_to_array = np.zeros((len(file_paths), size, size, channels), dtype='int64')\n",
    "        for ind, i in enumerate(file_paths):\n",
    "            # reads image\n",
    "            img = image_read(i)\n",
    "            all_images_to_array[ind] = img.astype('int64')\n",
    "        print('All Images shape: {} size: {:,}'.format(all_images_to_array.shape, all_images_to_array.size))\n",
    "    else:\n",
    "        all_images_to_array = np.zeros((len(file_paths), size[0], size[1], channels), dtype='int64')\n",
    "        for ind, i in enumerate(file_paths):\n",
    "            img = read_img(i)\n",
    "            all_images_to_array[ind] = img.astype('int64')\n",
    "        print('All Images shape: {} size: {:,}'.format(all_images_to_array.shape, all_images_to_array.size))\n",
    "    return all_images_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-a4715c6a5d17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfile_paths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'./images/*.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "file_paths = glob(r'./images/*.jpg')\n",
    "X_train = image_convert(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_lab(img, l=False, ab=False):\n",
    "    \"\"\"\n",
    "    Takes in RGB channels in range 0-255 and outputs L or AB channels in range -1 to 1\n",
    "    \"\"\"\n",
    "    img = img / 255\n",
    "    l = color.rgb2lab(img)[:,:,0]\n",
    "    l = l / 50 - 1\n",
    "    l = l[...,np.newaxis]\n",
    "\n",
    "    ab = color.rgb2lab(img)[:,:,1:]\n",
    "    ab = (ab + 128) / 255 * 2 - 1\n",
    "    if l:\n",
    "        return l\n",
    "    else: return ab\n",
    "\n",
    "def lab_to_rgb(img):\n",
    "    \"\"\"\n",
    "    Takes in LAB channels in range -1 to 1 and out puts RGB chanels in range 0-255\n",
    "    \"\"\"\n",
    "    new_img = np.zeros((256,256,3))\n",
    "    for i in range(len(img)):\n",
    "        for j in range(len(img[i])):\n",
    "            pix = img[i,j]\n",
    "            new_img[i,j] = [(pix[0] + 1) * 50,(pix[1] +1) / 2 * 255 - 128,(pix[2] +1) / 2 * 255 - 128]\n",
    "    new_img = color.lab2rgb(new_img) * 255\n",
    "    new_img = new_img.astype('uint8')\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = np.array([rgb_to_lab(image,l=True)for image in X_train])\n",
    "AB = np.array([rgb_to_lab(image,ab=True)for image in X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_AB_channels = (L,AB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('l_ab_channels.p','wb') as f:\n",
    "        pickle.dump(L_AB_channels,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_block(x ,num_conv=2, num_filters=512,kernel_size=(3,3),padding='same',strides=2):\n",
    "    '''\n",
    "    This function defines a ResNet Block composed of two convolution layers and that returns the sum of the inputs and the\n",
    "    convolution outputs.\n",
    "    Parameters\n",
    "    x: is the tensor which will be used as input to the convolution layer\n",
    "    num_conv: is the number of convolutions inside the block\n",
    "    num_filters: is an int that describes the number of output filters in the convolution\n",
    "    kernel size: is an int or tuple that describes the size of the convolution window\n",
    "    padding: padding with zeros the image so that the kernel fits the input image or not. Options: 'valid' or 'same'\n",
    "    strides: is the number of pixels shifts over the input matrix. \n",
    "    '''\n",
    "    input=x\n",
    "    for i in num_conv:\n",
    "        \n",
    "        input=Conv2D(num_filters,kernel_size=kernel_size,padding=padding,strides=strides)(input)\n",
    "        input=InstanceNormalization()(input)\n",
    "        input=LeakyReLU(0.2)(input)\n",
    "\n",
    "\n",
    "    return (input + x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(input,filters=64,num_enc_layers=4,num_resblock=4,name=\"Generator\"):\n",
    "    ''' \n",
    "    The generator per se is an autoencoder built by a series of convolution layers that initially extract features of the\n",
    "    input image.\n",
    "    '''\n",
    "\n",
    "    # defining input\n",
    "    input=Input(shape=(256,256,1))\n",
    "    x=input\n",
    "    \n",
    "    '''\n",
    "    Adding first layer of the encoder model: 64 filters, 5x5 kernel size, 2 so the input size is reduced to half,\n",
    "    input size is the image size: (256,256,1), number of channels 1 for the luminosity channel.\n",
    "    We will use InstanceNormalization through the model and Leaky Relu with and alfa of 0.2\n",
    "    as activation function for the encoder, while relu as activation for the decoder.\n",
    "    between both of them, in the latent space we insert 4 resnet blocks.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    for lay in num_enc_layers:\n",
    "    x=Conv2D(filters*lay,(5,5),padding='same',strides=2,input_shape=(256,256,1))(x)\n",
    "    x=InstanceNormalization()(x)\n",
    "    x=LeakyReLU(0.2)(x)\n",
    "    \n",
    "    x=Conv2D(128,(3,3),padding='same',strides=2)(x)\n",
    "    x=InstanceNormalization()(x)\n",
    "    x=LeakyReLU(0.2)(x)\n",
    "    \n",
    "    x=Conv2D(256,(3,3),padding='same',strides=2)(x)\n",
    "    x=InstanceNormalization()(x)\n",
    "    x=LeakyReLU(0.2)(x)\n",
    "    \n",
    "    x=Conv2D(512,(3,3),padding='same',strides=2)(x)\n",
    "    x=InstanceNormalization()(x)\n",
    "    x=LeakyReLU(0.2)(x)\n",
    "    \n",
    "    '''\n",
    "----------------------------------LATENT SPACE---------------------------------------------\n",
    "    '''\n",
    "    for r in num_resblock:\n",
    "        x=resnet_block(x)    \n",
    "    '''\n",
    "----------------------------------LATENT SPACE---------------------------------------------\n",
    "    '''\n",
    "    \n",
    "    x=Conv2DTranspose(256,(3,3),padding='same',strides=2)(x)\n",
    "    x=InstanceNormalization()(x)\n",
    "    x=Activation('relu')(x)\n",
    "              \n",
    "    x=Conv2DTranspose(128,(3,3),padding='same',strides=2)(x)\n",
    "    x=InstanceNormalization()(x)\n",
    "    x=Activation('relu')(x)\n",
    "    \n",
    "    x=Conv2DTranspose(64,(3,3),padding='same',strides=2)(x)\n",
    "    x=InstanceNormalization()(x)\n",
    "    x=Activation('relu')(x)\n",
    "              \n",
    "    x=Conv2DTranspose(32,(5,5),padding='same',strides=2)(x)\n",
    "    x=InstanceNormalization()(x)\n",
    "    x=Activation('relu')(x)\n",
    "    \n",
    "    x=Conv2D(2,(3,3),padding='same')(x)\n",
    "    output=Activation('tanh')(x)\n",
    "    \n",
    "    model=Model(input,output,name=name)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(input,name=\"Discriminator\"):\n",
    "    # importing libraries\n",
    "    from keras.layers import Conv2D, MaxPooling2D, Activation, BatchNormalization, UpSampling2D, Dropout, Flatten, Dense, Input, LeakyReLU, Conv2DTranspose,AveragePooling2D, Concatenate\n",
    "    from tensorflow_addons import InstanceNormalization\n",
    "    \n",
    "    # defining input\n",
    "    input=Input(shape=(256,256,2))\n",
    "    x=input\n",
    "    \n",
    "    x=Conv2D(32,(3,3), padding='same',strides=2,input_shape=(256,256,2))(x)\n",
    "    x=LeakyReLU(0.2)(x)\n",
    "    x=Dropout(0.25)(x)\n",
    "        \n",
    "    x=Conv2D(64,(3,3),padding='same',strides=2)(x)\n",
    "    x=BatchNormalization()\n",
    "    x=LeakyReLU(0.2)(x)\n",
    "    x=Dropout(0.25)(x)\n",
    "        \n",
    "        \n",
    "    x=Conv2D(128,(3,3), padding='same', strides=2)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=LeakyReLU(0.2)(x)\n",
    "    x=Dropout(0.25)(x)\n",
    "        \n",
    "        \n",
    "    x=Conv2D(256,(3,3), padding='same',strides=2)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=LeakyReLU(0.2)(x)\n",
    "    x=Dropout(0.25)(x)\n",
    "        \n",
    "        \n",
    "    x=Flatten()(x)\n",
    "    x=Dense(1)(x)\n",
    "    output=Activation('sigmoid')(x)\n",
    "        \n",
    "    model=Model(input,output,name=name)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building GAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f7c572b85af0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Building discriminators\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdiscriminator_A\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_a\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"discriminator_A\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdiscriminator_B\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_b\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"discriminator_A\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_a' is not defined"
     ]
    }
   ],
   "source": [
    "# Building discriminators\n",
    "discriminator_A=discriminator(input_a,\"discriminator_A\")\n",
    "\n",
    "discriminator_B=discriminator(input_b,\"discriminator_A\")\n",
    "\n",
    "discriminator_A.trainable = False\n",
    "\n",
    "discriminator_B.trainable = False\n",
    "\n",
    "# Building generator\n",
    "generator_B = generator(input_a,\"Generator_A_B\")\n",
    "generator_A = generator(input_b,\"Generator_B_A\")\n",
    "\n",
    "decision_A=discriminator(generator_a,\"Discriminator_A\")\n",
    "decision_B=discriminator(generator_B,\"Discriminator_B\")\n",
    "\n",
    "cycle_A=generator(generator_b,\"Generator_B_A\")\n",
    "cycle_B=generator(generator_A,\"Generator_A_B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates lists to log the losses and accuracy\n",
    "gen_losses = []\n",
    "disc_real_losses = []\n",
    "disc_fake_losses=[] \n",
    "disc_acc = []\n",
    "\n",
    "#train the generator on a full set of 320 and the discriminator on a half set of 160 for each epoch\n",
    "#discriminator is given real and fake y's while generator is always given real y's\n",
    "\n",
    "n = 320\n",
    "y_train_fake = np.zeros([160,1])\n",
    "y_train_real = np.ones([160,1])\n",
    "y_gen = np.ones([n,1])\n",
    "\n",
    "#Optional label smoothing\n",
    "#y_train_real -= .1\n",
    "\n",
    "\n",
    "#Pick batch size and number of epochs, number of epochs depends on the number of photos per epoch set above\n",
    "num_epochs=1500\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-494a6aa0639b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#run and train until photos meet expectations (stop & restart model with tweaks if loss goes to 0 in discriminator)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;31m#shuffle L and AB channels then take a subset corresponding to each networks training size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_L\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train_L\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "#run and train until photos meet expectations (stop & restart model with tweaks if loss goes to 0 in discriminator)\n",
    "for epoch in tqdm(range(1,num_epochs+1)):\n",
    "    #shuffle L and AB channels then take a subset corresponding to each networks training size\n",
    "    np.random.shuffle(X_train_L)\n",
    "    l = X_train_L[:n]\n",
    "    np.random.shuffle(X_train_AB)\n",
    "    ab = X_train_AB[:160]\n",
    "    \n",
    "    fake_images = generator.predict(l[:160], verbose=1)\n",
    "    \n",
    "    #Train on Real AB channels\n",
    "    d_loss_real = discriminator.fit(x=ab, y= y_train_real,batch_size=32,epochs=1,verbose=1) \n",
    "    disc_real_losses.append(d_loss_real.history['loss'][-1])\n",
    "    \n",
    "    #Train on fake AB channels\n",
    "    d_loss_fake = discriminator.fit(x=fake_images,y=y_train_fake,batch_size=32,epochs=1,verbose=1)\n",
    "    disc_fake_losses.append(d_loss_fake.history['loss'][-1])\n",
    "    \n",
    "    #append the loss and accuracy and print loss\n",
    "    disc_acc.append(d_loss_fake.history['acc'][-1])\n",
    "    \n",
    "\n",
    "    #Train the gan by producing AB channels from L\n",
    "    g_loss = combined_network.fit(x=l, y=y_gen,batch_size=32,epochs=1,verbose=1)\n",
    "    #append and print generator loss\n",
    "    gen_losses.append(g_loss.history['loss'][-1])\n",
    "   \n",
    "    #every 50 epochs it prints a generated photo and every 100 it saves the model under that epoch\n",
    "    if epoch % 50 == 0:\n",
    "        print('Reached epoch:',epoch)\n",
    "        pred = generator.predict(X_test_L[2].reshape(1,256,256,1))\n",
    "        img = lab_to_rgb(np.dstack((X_test_L[2],pred.reshape(256,256,2))))\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        if epoch % 100 == 0:\n",
    "              generator.save('generator_' + str(epoch)+ '_v3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 256\n",
    "img_width = 256\n",
    "img_layer = 3\n",
    "img_size = img_height * img_width\n",
    "\n",
    "to_train = True\n",
    "to_test = False\n",
    "to_restore = False\n",
    "output_path = \"./output\"\n",
    "check_dir = \"./output/checkpoints/\"\n",
    "\n",
    "\n",
    "temp_check = 0\n",
    "\n",
    "\n",
    "\n",
    "max_epoch = 1\n",
    "max_images = 100\n",
    "\n",
    "h1_size = 150\n",
    "h2_size = 300\n",
    "z_size = 100\n",
    "batch_size = 1\n",
    "pool_size = 50\n",
    "sample_size = 10\n",
    "save_training_images = True\n",
    "ngf = 32\n",
    "ndf = 64\n",
    "\n",
    "class CycleGAN():\n",
    "\n",
    "    def input_setup(self):\n",
    "\n",
    "        ''' \n",
    "        This function basically setup variables for taking image input.\n",
    "        filenames_A/filenames_B -> takes the list of all training images\n",
    "        self.image_A/self.image_B -> Input image with each values ranging from [-1,1]\n",
    "        '''\n",
    "\n",
    "        filenames_A = tf.train.match_filenames_once(\"./input/horse2zebra/trainA/*.jpg\")    \n",
    "        self.queue_length_A = tf.size(filenames_A)\n",
    "        filenames_B = tf.train.match_filenames_once(\"./input/horse2zebra/trainB/*.jpg\")    \n",
    "        self.queue_length_B = tf.size(filenames_B)\n",
    "        \n",
    "        filename_queue_A = tf.train.string_input_producer(filenames_A)\n",
    "        filename_queue_B = tf.train.string_input_producer(filenames_B)\n",
    "\n",
    "        image_reader = tf.WholeFileReader()\n",
    "        _, image_file_A = image_reader.read(filename_queue_A)\n",
    "        _, image_file_B = image_reader.read(filename_queue_B)\n",
    "\n",
    "        self.image_A = tf.subtract(tf.div(tf.image.resize_images(tf.image.decode_jpeg(image_file_A),[256,256]),127.5),1)\n",
    "        self.image_B = tf.subtract(tf.div(tf.image.resize_images(tf.image.decode_jpeg(image_file_B),[256,256]),127.5),1)\n",
    "\n",
    "    \n",
    "\n",
    "    def input_read(self, sess):\n",
    "\n",
    "\n",
    "        '''\n",
    "        It reads the input into from the image folder.\n",
    "        self.fake_images_A/self.fake_images_B -> List of generated images used for calculation of loss function of Discriminator\n",
    "        self.A_input/self.B_input -> Stores all the training images in python list\n",
    "        '''\n",
    "\n",
    "        # Loading images into the tensors\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "        num_files_A = sess.run(self.queue_length_A)\n",
    "        num_files_B = sess.run(self.queue_length_B)\n",
    "\n",
    "        self.fake_images_A = np.zeros((pool_size,1,img_height, img_width, img_layer))\n",
    "        self.fake_images_B = np.zeros((pool_size,1,img_height, img_width, img_layer))\n",
    "\n",
    "\n",
    "        self.A_input = np.zeros((max_images, batch_size, img_height, img_width, img_layer))\n",
    "        self.B_input = np.zeros((max_images, batch_size, img_height, img_width, img_layer))\n",
    "\n",
    "        for i in range(max_images): \n",
    "            image_tensor = sess.run(self.image_A)\n",
    "            if(image_tensor.size() == img_size*batch_size*img_layer):\n",
    "                self.A_input[i] = image_tensor.reshape((batch_size,img_height, img_width, img_layer))\n",
    "\n",
    "        for i in range(max_images):\n",
    "            image_tensor = sess.run(self.image_B)\n",
    "            if(image_tensor.size() == img_size*batch_size*img_layer):\n",
    "                self.B_input[i] = image_tensor.reshape((batch_size,img_height, img_width, img_layer))\n",
    "\n",
    "\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def model_setup(self):\n",
    "\n",
    "        ''' This function sets up the model to train\n",
    "        self.input_A/self.input_B -> Set of training images.\n",
    "        self.fake_A/self.fake_B -> Generated images by corresponding generator of input_A and input_B\n",
    "        self.lr -> Learning rate variable\n",
    "        self.cyc_A/ self.cyc_B -> Images generated after feeding self.fake_A/self.fake_B to corresponding generator. This is use to calcualte cyclic loss\n",
    "        '''\n",
    "\n",
    "        self.input_A = tf.placeholder(tf.float32, [batch_size, img_width, img_height, img_layer], name=\"input_A\")\n",
    "        self.input_B = tf.placeholder(tf.float32, [batch_size, img_width, img_height, img_layer], name=\"input_B\")\n",
    "        \n",
    "        self.fake_pool_A = tf.placeholder(tf.float32, [None, img_width, img_height, img_layer], name=\"fake_pool_A\")\n",
    "        self.fake_pool_B = tf.placeholder(tf.float32, [None, img_width, img_height, img_layer], name=\"fake_pool_B\")\n",
    "\n",
    "        self.global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "\n",
    "        self.num_fake_inputs = 0\n",
    "\n",
    "        self.lr = tf.placeholder(tf.float32, shape=[], name=\"lr\")\n",
    "\n",
    "        with tf.variable_scope(\"Model\") as scope:\n",
    "            self.fake_B = build_generator_resnet_9blocks(self.input_A, name=\"g_A\")\n",
    "            self.fake_A = build_generator_resnet_9blocks(self.input_B, name=\"g_B\")\n",
    "            self.rec_A = build_gen_discriminator(self.input_A, \"d_A\")\n",
    "            self.rec_B = build_gen_discriminator(self.input_B, \"d_B\")\n",
    "\n",
    "            scope.reuse_variables()\n",
    "\n",
    "            self.fake_rec_A = build_gen_discriminator(self.fake_A, \"d_A\")\n",
    "            self.fake_rec_B = build_gen_discriminator(self.fake_B, \"d_B\")\n",
    "            self.cyc_A = build_generator_resnet_9blocks(self.fake_B, \"g_B\")\n",
    "            self.cyc_B = build_generator_resnet_9blocks(self.fake_A, \"g_A\")\n",
    "\n",
    "            scope.reuse_variables()\n",
    "\n",
    "            self.fake_pool_rec_A = build_gen_discriminator(self.fake_pool_A, \"d_A\")\n",
    "            self.fake_pool_rec_B = build_gen_discriminator(self.fake_pool_B, \"d_B\")\n",
    "\n",
    "    def loss_calc(self):\n",
    "\n",
    "        ''' In this function we are defining the variables for loss calcultions and traning model\n",
    "        d_loss_A/d_loss_B -> loss for discriminator A/B\n",
    "        g_loss_A/g_loss_B -> loss for generator A/B\n",
    "        *_trainer -> Variaous trainer for above loss functions\n",
    "        *_summ -> Summary variables for above loss functions'''\n",
    "\n",
    "        cyc_loss = tf.reduce_mean(tf.abs(self.input_A-self.cyc_A)) + tf.reduce_mean(tf.abs(self.input_B-self.cyc_B))\n",
    "        \n",
    "        disc_loss_A = tf.reduce_mean(tf.squared_difference(self.fake_rec_A,1))\n",
    "        disc_loss_B = tf.reduce_mean(tf.squared_difference(self.fake_rec_B,1))\n",
    "        \n",
    "        g_loss_A = cyc_loss*10 + disc_loss_B\n",
    "        g_loss_B = cyc_loss*10 + disc_loss_A\n",
    "\n",
    "        d_loss_A = (tf.reduce_mean(tf.square(self.fake_pool_rec_A)) + tf.reduce_mean(tf.squared_difference(self.rec_A,1)))/2.0\n",
    "        d_loss_B = (tf.reduce_mean(tf.square(self.fake_pool_rec_B)) + tf.reduce_mean(tf.squared_difference(self.rec_B,1)))/2.0\n",
    "\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(self.lr, beta1=0.5)\n",
    "\n",
    "        self.model_vars = tf.trainable_variables()\n",
    "\n",
    "        d_A_vars = [var for var in self.model_vars if 'd_A' in var.name]\n",
    "        g_A_vars = [var for var in self.model_vars if 'g_A' in var.name]\n",
    "        d_B_vars = [var for var in self.model_vars if 'd_B' in var.name]\n",
    "        g_B_vars = [var for var in self.model_vars if 'g_B' in var.name]\n",
    "        \n",
    "        self.d_A_trainer = optimizer.minimize(d_loss_A, var_list=d_A_vars)\n",
    "        self.d_B_trainer = optimizer.minimize(d_loss_B, var_list=d_B_vars)\n",
    "        self.g_A_trainer = optimizer.minimize(g_loss_A, var_list=g_A_vars)\n",
    "        self.g_B_trainer = optimizer.minimize(g_loss_B, var_list=g_B_vars)\n",
    "\n",
    "        for var in self.model_vars: print(var.name)\n",
    "\n",
    "        #Summary variables for tensorboard\n",
    "\n",
    "        self.g_A_loss_summ = tf.summary.scalar(\"g_A_loss\", g_loss_A)\n",
    "        self.g_B_loss_summ = tf.summary.scalar(\"g_B_loss\", g_loss_B)\n",
    "        self.d_A_loss_summ = tf.summary.scalar(\"d_A_loss\", d_loss_A)\n",
    "        self.d_B_loss_summ = tf.summary.scalar(\"d_B_loss\", d_loss_B)\n",
    "\n",
    "    def save_training_images(self, sess, epoch):\n",
    "\n",
    "        if not os.path.exists(\"./output/imgs\"):\n",
    "            os.makedirs(\"./output/imgs\")\n",
    "\n",
    "        for i in range(0,10):\n",
    "            fake_A_temp, fake_B_temp, cyc_A_temp, cyc_B_temp = sess.run([self.fake_A, self.fake_B, self.cyc_A, self.cyc_B],feed_dict={self.input_A:self.A_input[i], self.input_B:self.B_input[i]})\n",
    "            imsave(\"./output/imgs/fakeB_\"+ str(epoch) + \"_\" + str(i)+\".jpg\",((fake_A_temp[0]+1)*127.5).astype(np.uint8))\n",
    "            imsave(\"./output/imgs/fakeA_\"+ str(epoch) + \"_\" + str(i)+\".jpg\",((fake_B_temp[0]+1)*127.5).astype(np.uint8))\n",
    "            imsave(\"./output/imgs/cycA_\"+ str(epoch) + \"_\" + str(i)+\".jpg\",((cyc_A_temp[0]+1)*127.5).astype(np.uint8))\n",
    "            imsave(\"./output/imgs/cycB_\"+ str(epoch) + \"_\" + str(i)+\".jpg\",((cyc_B_temp[0]+1)*127.5).astype(np.uint8))\n",
    "            imsave(\"./output/imgs/inputA_\"+ str(epoch) + \"_\" + str(i)+\".jpg\",((self.A_input[i][0]+1)*127.5).astype(np.uint8))\n",
    "            imsave(\"./output/imgs/inputB_\"+ str(epoch) + \"_\" + str(i)+\".jpg\",((self.B_input[i][0]+1)*127.5).astype(np.uint8))\n",
    "\n",
    "    def fake_image_pool(self, num_fakes, fake, fake_pool):\n",
    "        ''' This function saves the generated image to corresponding pool of images.\n",
    "        In starting. It keeps on feeling the pool till it is full and then randomly selects an\n",
    "        already stored image and replace it with new one.'''\n",
    "\n",
    "        if(num_fakes < pool_size):\n",
    "            fake_pool[num_fakes] = fake\n",
    "            return fake\n",
    "        else :\n",
    "            p = random.random()\n",
    "            if p > 0.5:\n",
    "                random_id = random.randint(0,pool_size-1)\n",
    "                temp = fake_pool[random_id]\n",
    "                fake_pool[random_id] = fake\n",
    "                return temp\n",
    "            else :\n",
    "                return fake\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "\n",
    "        ''' Training Function '''\n",
    "\n",
    "\n",
    "        # Load Dataset from the dataset folder\n",
    "        self.input_setup()  \n",
    "\n",
    "        #Build the network\n",
    "        self.model_setup()\n",
    "\n",
    "        #Loss function calculations\n",
    "        self.loss_calc()\n",
    "      \n",
    "        # Initializing the global variables\n",
    "        init = tf.global_variables_initializer()\n",
    "        saver = tf.train.Saver()     \n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "\n",
    "            #Read input to nd array\n",
    "            self.input_read(sess)\n",
    "\n",
    "            #Restore the model to run the model from last checkpoint\n",
    "            if to_restore:\n",
    "                chkpt_fname = tf.train.latest_checkpoint(check_dir)\n",
    "                saver.restore(sess, chkpt_fname)\n",
    "\n",
    "            writer = tf.summary.FileWriter(\"./output/2\")\n",
    "\n",
    "            if not os.path.exists(check_dir):\n",
    "                os.makedirs(check_dir)\n",
    "\n",
    "            # Training Loop\n",
    "            for epoch in range(sess.run(self.global_step),100):                \n",
    "                print (\"In the epoch \", epoch)\n",
    "                saver.save(sess,os.path.join(check_dir,\"cyclegan\"),global_step=epoch)\n",
    "\n",
    "                # Dealing with the learning rate as per the epoch number\n",
    "                if(epoch < 100) :\n",
    "                    curr_lr = 0.0002\n",
    "                else:\n",
    "                    curr_lr = 0.0002 - 0.0002*(epoch-100)/100\n",
    "\n",
    "                if(save_training_images):\n",
    "                    self.save_training_images(sess, epoch)\n",
    "\n",
    "                # sys.exit()\n",
    "\n",
    "                for ptr in range(0,max_images):\n",
    "                    print(\"In the iteration \",ptr)\n",
    "                    print(\"Starting\",time.time()*1000.0)\n",
    "\n",
    "                    # Optimizing the G_A network\n",
    "\n",
    "                    _, fake_B_temp, summary_str = sess.run([self.g_A_trainer, self.fake_B, self.g_A_loss_summ],feed_dict={self.input_A:self.A_input[ptr], self.input_B:self.B_input[ptr], self.lr:curr_lr})\n",
    "                    \n",
    "                    writer.add_summary(summary_str, epoch*max_images + ptr)                    \n",
    "                    fake_B_temp1 = self.fake_image_pool(self.num_fake_inputs, fake_B_temp, self.fake_images_B)\n",
    "                    \n",
    "                    # Optimizing the D_B network\n",
    "                    _, summary_str = sess.run([self.d_B_trainer, self.d_B_loss_summ],feed_dict={self.input_A:self.A_input[ptr], self.input_B:self.B_input[ptr], self.lr:curr_lr, self.fake_pool_B:fake_B_temp1})\n",
    "                    writer.add_summary(summary_str, epoch*max_images + ptr)\n",
    "                    \n",
    "                    \n",
    "                    # Optimizing the G_B network\n",
    "                    _, fake_A_temp, summary_str = sess.run([self.g_B_trainer, self.fake_A, self.g_B_loss_summ],feed_dict={self.input_A:self.A_input[ptr], self.input_B:self.B_input[ptr], self.lr:curr_lr})\n",
    "\n",
    "                    writer.add_summary(summary_str, epoch*max_images + ptr)\n",
    "                    \n",
    "                    \n",
    "                    fake_A_temp1 = self.fake_image_pool(self.num_fake_inputs, fake_A_temp, self.fake_images_A)\n",
    "\n",
    "                    # Optimizing the D_A network\n",
    "                    _, summary_str = sess.run([self.d_A_trainer, self.d_A_loss_summ],feed_dict={self.input_A:self.A_input[ptr], self.input_B:self.B_input[ptr], self.lr:curr_lr, self.fake_pool_A:fake_A_temp1})\n",
    "\n",
    "                    writer.add_summary(summary_str, epoch*max_images + ptr)\n",
    "                    \n",
    "                    self.num_fake_inputs+=1\n",
    "            \n",
    "                        \n",
    "\n",
    "                sess.run(tf.assign(self.global_step, epoch + 1))\n",
    "\n",
    "            writer.add_graph(sess.graph)\n",
    "\n",
    "    def test(self):\n",
    "\n",
    "\n",
    "        ''' Testing Function'''\n",
    "\n",
    "        print(\"Testing the results\")\n",
    "\n",
    "        self.input_setup()\n",
    "\n",
    "        self.model_setup()\n",
    "        saver = tf.train.Saver()\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            sess.run(init)\n",
    "\n",
    "            self.input_read(sess)\n",
    "\n",
    "            chkpt_fname = tf.train.latest_checkpoint(check_dir)\n",
    "            saver.restore(sess, chkpt_fname)\n",
    "\n",
    "            if not os.path.exists(\"./output/imgs/test/\"):\n",
    "                os.makedirs(\"./output/imgs/test/\")            \n",
    "\n",
    "            for i in range(0,100):\n",
    "                fake_A_temp, fake_B_temp = sess.run([self.fake_A, self.fake_B],feed_dict={self.input_A:self.A_input[i], self.input_B:self.B_input[i]})\n",
    "                imsave(\"./output/imgs/test/fakeB_\"+str(i)+\".jpg\",((fake_A_temp[0]+1)*127.5).astype(np.uint8))\n",
    "                imsave(\"./output/imgs/test/fakeA_\"+str(i)+\".jpg\",((fake_B_temp[0]+1)*127.5).astype(np.uint8))\n",
    "                imsave(\"./output/imgs/test/inputA_\"+str(i)+\".jpg\",((self.A_input[i][0]+1)*127.5).astype(np.uint8))\n",
    "                imsave(\"./output/imgs/test/inputB_\"+str(i)+\".jpg\",((self.B_input[i][0]+1)*127.5).astype(np.uint8))\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    model = CycleGAN()\n",
    "    if to_train:\n",
    "        model.train()\n",
    "    elif to_test:\n",
    "        model.test()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
